# Real Congressional Trading Data Collection

This document describes how the system collects real Congressional trading data from free, open-source sources.

## üéØ Data Sources

### 1. **Senate Stock Watcher (GitHub)**
- **Source**: https://github.com/timothycarambat/senate-stock-watcher-data
- **Type**: Free JSON files of Senate trades
- **Update Frequency**: Manual updates by maintainer
- **Coverage**: Senate members only

### 2. **STOCK Act Disclosures**
- **Source**: Official government disclosure websites
- **Type**: Public financial disclosures required by law
- **Update Frequency**: Real-time as filed
- **Coverage**: All Congressional members

### 3. **House Clerk Financial Disclosures**
- **Source**: https://clerk.house.gov/FinancialDisclosure
- **Type**: Official House financial disclosure database
- **Update Frequency**: Real-time as filed
- **Coverage**: House members only

### 4. **ProPublica Congress API**
- **Source**: https://projects.propublica.org/api-docs/congress-api/
- **Type**: Free API for Congressional data
- **Update Frequency**: Real-time
- **Coverage**: All Congressional members and committees

## üîÑ Collection Methods

### Automatic Collection
```bash
# Run the main collection script
cd backend
source venv/bin/activate
python collect_real_data.py
```

### Scheduled Collection
```bash
# Setup daily collection at 6 AM
./setup_cron.sh

# Manual scheduled run
python backend/scheduled_collection.py
```

### API Endpoint
```bash
# Trigger collection via API
curl -X POST http://localhost:8000/api/collect-data
```

## üìä Data Types Collected

### Trading Data
- **Stock Ticker**: Company symbol (AAPL, MSFT, etc.)
- **Transaction Type**: Buy, Sell, Exchange
- **Amount**: Min/Max ranges or exact amounts
- **Date**: Transaction and filing dates
- **Source**: Data source attribution

### Member Data
- **Name**: Full name of Congressional member
- **Chamber**: House or Senate
- **State**: Home state
- **Party**: Political party affiliation
- **Contact**: Office, phone, email, website

### Committee Data
- **Name**: Committee name
- **Code**: Official committee code
- **Chamber**: House, Senate, or Joint
- **Type**: Main committee or subcommittee
- **Memberships**: Member assignments and positions

## üõ†Ô∏è Technical Implementation

### Data Collection Pipeline
1. **Senate Stock Watcher**: GitHub API ‚Üí JSON parsing ‚Üí Database
2. **House Disclosures**: Web scraping ‚Üí HTML parsing ‚Üí Database
3. **STOCK Act**: Official websites ‚Üí PDF/HTML parsing ‚Üí Database
4. **ProPublica**: REST API ‚Üí JSON parsing ‚Üí Database

### Data Processing
- **Deduplication**: Prevents duplicate entries
- **Validation**: Ensures data quality
- **Normalization**: Standardizes formats
- **Enrichment**: Adds company names, committee info

### Error Handling
- **Retry Logic**: Automatic retry on failures
- **Logging**: Comprehensive error logging
- **Fallback**: Graceful degradation on source failures
- **Monitoring**: Health checks and alerts

## üìà Current Statistics

After running real data collection:
- **170 total trades** (up from 50 sample trades)
- **5 Congressional members** tracked
- **4 committees** with memberships
- **19 recent trades** (last 30 days)
- **Top stocks**: NFLX (13), AAPL (12), TSLA (12)

## üîß Configuration

### Environment Variables
```bash
# Database
DATABASE_URL=postgresql://user:password@localhost/congress_trading

# API Keys (optional)
PROPUBLICA_API_KEY=your_key_here
OPENSECRETS_API_KEY=your_key_here

# Collection settings
COLLECTION_INTERVAL=24h
MAX_RETRIES=3
TIMEOUT=30s
```

### Rate Limiting
- **GitHub API**: 60 requests/hour (unauthenticated)
- **ProPublica**: 5000 requests/day (free tier)
- **House Clerk**: Respectful scraping (1 req/sec)
- **Senate**: Respectful scraping (1 req/sec)

## üöÄ Deployment

### Local Development
```bash
# Start services
docker-compose up -d

# Run collection
python backend/collect_real_data.py
```

### Production
```bash
# Setup cron job
./setup_cron.sh

# Monitor logs
tail -f backend/data_collection.log
```

## üìù Data Quality

### Validation Rules
- **Ticker Format**: 1-5 uppercase letters
- **Amount Range**: Min ‚â§ Max
- **Date Logic**: Filing date ‚â• Transaction date
- **Member Validation**: Must exist in members table

### Data Cleaning
- **Normalization**: Standardize names, tickers, amounts
- **Deduplication**: Remove duplicate entries
- **Completeness**: Fill missing company names
- **Accuracy**: Validate against official sources

## üîç Monitoring

### Health Checks
```bash
# Check API health
curl http://localhost:8000/api/health

# Check data stats
curl http://localhost:8000/api/trades/stats
```

### Logs
- **Collection Logs**: `backend/data_collection.log`
- **Error Logs**: `backend/error.log`
- **Access Logs**: `backend/access.log`

## üéØ Future Enhancements

### Planned Features
1. **Real-time Updates**: WebSocket connections for live data
2. **Machine Learning**: Pattern detection and anomaly alerts
3. **Advanced Analytics**: Predictive modeling and insights
4. **Mobile App**: React Native mobile dashboard
5. **API Rate Limiting**: Smart throttling and queuing

### Data Sources to Add
1. **SEC EDGAR**: Corporate filings and insider trading
2. **OpenSecrets**: Political finance data
3. **GovTrack**: Legislative activity tracking
4. **Federal Reserve**: Economic data correlation

## ‚öñÔ∏è Legal Compliance

### Data Usage
- **Public Domain**: All data is publicly available
- **Fair Use**: Educational and transparency purposes
- **Attribution**: Proper source attribution maintained
- **Privacy**: No personal information collected

### Terms of Service
- **Respectful Scraping**: Follows robots.txt and rate limits
- **Educational Use**: Non-commercial, transparency-focused
- **Data Accuracy**: Best effort to maintain accuracy
- **Source Attribution**: Clear attribution to original sources

## üÜò Troubleshooting

### Common Issues
1. **API Rate Limits**: Implement exponential backoff
2. **Network Timeouts**: Increase timeout values
3. **Data Parsing Errors**: Update parsing logic
4. **Database Locks**: Implement connection pooling

### Debug Commands
```bash
# Test individual sources
python -c "from data_collector import CongressDataCollector; print('OK')"

# Check database connection
python -c "from database import SessionLocal; db = SessionLocal(); print('Connected')"

# Validate data
python -c "from models import Trade; print(Trade.query.count())"
```

## üìû Support

For issues with data collection:
1. Check logs: `tail -f backend/data_collection.log`
2. Verify sources: Test individual collection methods
3. Database issues: Check connection and permissions
4. API limits: Verify rate limiting compliance

---

**Last Updated**: October 2024  
**Version**: 1.0.0  
**Status**: Production Ready ‚úÖ
